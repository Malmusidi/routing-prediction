{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train Routing Disagreement Prediction Models\n",
        "\n",
        "This notebook trains Random Forest models to predict pedestrian routing disagreements among Google Maps, ArcGIS, and OpenRouteService.\n",
        "\n",
        "**Use this notebook if you want to:**\n",
        "- Train models on your own study area\n",
        "- Modify classification thresholds\n",
        "- Experiment with different features or algorithms\n",
        "\n",
        "**If you just want to use the pre-trained models, use `03_apply_pretrained_models.ipynb` instead.**\n",
        "\n",
        "## Requirements\n",
        "- Dataset with routing estimates from all 3 platforms (ORS, ArcGIS, Google Maps)\n",
        "- The 6 predictor features (generated using `01_generate_predictors.ipynb`)"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Install Dependencies"
      ],
      "metadata": {
        "id": "install"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn pandas numpy matplotlib seaborn joblib -q\n",
        "print(\"✓ Dependencies installed\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Configuration"
      ],
      "metadata": {
        "id": "config"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration Settings { display-mode: \"form\" }\n",
        "\n",
        "# ============================================================================\n",
        "# FILE PATHS\n",
        "# ============================================================================\n",
        "INPUT_CSV = '/content/your_data_with_routing.csv'  #@param {type:\"string\"}\n",
        "MODEL_OUTPUT_DIR = '/content/models/'  #@param {type:\"string\"}\n",
        "\n",
        "# ============================================================================\n",
        "# FEATURE COLUMNS - The 6 predictors\n",
        "# ============================================================================\n",
        "FEATURE_COLS = [\n",
        "    'Straight_Line_Distance_m',\n",
        "    'Origin_Road_Length_Density_m_km2',\n",
        "    'Dest_Intersection_Density_n_km2',\n",
        "    'Slope_Pct',\n",
        "    'Elevation_Difference_m',\n",
        "    'Population'\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# ROUTING COLUMNS - Update to match your column names\n",
        "# ============================================================================\n",
        "# Distance columns from each platform\n",
        "DISTANCE_COLS = ['ORS_Dist_m', 'Arc_Dist_m', 'GMaps_Dist_m']\n",
        "\n",
        "# Time columns from each platform\n",
        "TIME_COLS = ['ORS_Time_min', 'Arc_Time_min', 'GMaps_Time_min']\n",
        "\n",
        "# ============================================================================\n",
        "# CLASSIFICATION THRESHOLDS\n",
        "# ============================================================================\n",
        "DISTANCE_THRESHOLD = 5   #@param {type:\"integer\"}\n",
        "TIME_THRESHOLD = 20      #@param {type:\"integer\"}\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL PARAMETERS\n",
        "# ============================================================================\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.20\n",
        "\n",
        "import os\n",
        "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Configuration loaded!\")\n",
        "print(f\"  Distance threshold: {DISTANCE_THRESHOLD}%\")\n",
        "print(f\"  Time threshold: {TIME_THRESHOLD}%\")"
      ],
      "metadata": {
        "id": "config_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Prepare Data"
      ],
      "metadata": {
        "id": "load"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score,\n",
        "                              precision_score, recall_score, confusion_matrix,\n",
        "                              roc_curve, classification_report)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ Libraries imported\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "print(f\"✓ Loaded {len(df):,} records\")\n",
        "\n",
        "# Verify columns\n",
        "all_required = FEATURE_COLS + DISTANCE_COLS + TIME_COLS\n",
        "missing = [c for c in all_required if c not in df.columns]\n",
        "if missing:\n",
        "    print(f\"\\n⚠️ Missing columns: {missing}\")\n",
        "    print(f\"Available columns: {list(df.columns)}\")\n",
        "else:\n",
        "    print(\"✓ All required columns found\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate disagreement ratios\n",
        "def calculate_disagreement(df, cols):\n",
        "    \"\"\"Calculate max disagreement ratio between platforms\"\"\"\n",
        "    data = df[cols]\n",
        "    min_vals = data.min(axis=1)\n",
        "    max_vals = data.max(axis=1)\n",
        "    return ((max_vals - min_vals) / min_vals) * 100\n",
        "\n",
        "# Prepare distance model data\n",
        "complete_dist = df[FEATURE_COLS + DISTANCE_COLS].dropna()\n",
        "disagreement_dist = calculate_disagreement(complete_dist, DISTANCE_COLS)\n",
        "y_dist = (disagreement_dist >= DISTANCE_THRESHOLD).astype(int)\n",
        "X_dist = complete_dist[FEATURE_COLS]\n",
        "\n",
        "print(f\"\\nDISTANCE MODEL (threshold: {DISTANCE_THRESHOLD}%)\")\n",
        "print(f\"  Complete cases: {len(X_dist):,}\")\n",
        "print(f\"  Agreement (0): {(y_dist==0).sum():,} ({(y_dist==0).mean():.1%})\")\n",
        "print(f\"  Disagreement (1): {(y_dist==1).sum():,} ({(y_dist==1).mean():.1%})\")\n",
        "\n",
        "# Prepare time model data\n",
        "complete_time = df[FEATURE_COLS + TIME_COLS].dropna()\n",
        "disagreement_time = calculate_disagreement(complete_time, TIME_COLS)\n",
        "y_time = (disagreement_time >= TIME_THRESHOLD).astype(int)\n",
        "X_time = complete_time[FEATURE_COLS]\n",
        "\n",
        "print(f\"\\nTIME MODEL (threshold: {TIME_THRESHOLD}%)\")\n",
        "print(f\"  Complete cases: {len(X_time):,}\")\n",
        "print(f\"  Agreement (0): {(y_time==0).sum():,} ({(y_time==0).mean():.1%})\")\n",
        "print(f\"  Disagreement (1): {(y_time==1).sum():,} ({(y_time==1).mean():.1%})\")"
      ],
      "metadata": {
        "id": "prepare_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Train/Test Split"
      ],
      "metadata": {
        "id": "split"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified train/test split\n",
        "X_train_dist, X_test_dist, y_train_dist, y_test_dist = train_test_split(\n",
        "    X_dist, y_dist,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_dist\n",
        ")\n",
        "\n",
        "X_train_time, X_test_time, y_train_time, y_test_time = train_test_split(\n",
        "    X_time, y_time,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_time\n",
        ")\n",
        "\n",
        "print(f\"Distance Model: Train={len(X_train_dist):,}, Test={len(X_test_dist):,}\")\n",
        "print(f\"Time Model: Train={len(X_train_time):,}, Test={len(X_test_time):,}\")"
      ],
      "metadata": {
        "id": "split_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Train Models"
      ],
      "metadata": {
        "id": "train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distance model parameters\n",
        "distance_params = {\n",
        "    'n_estimators': 300,\n",
        "    'class_weight': 'balanced',\n",
        "    'max_depth': 12,\n",
        "    'max_features': 'sqrt',\n",
        "    'min_samples_leaf': 3,\n",
        "    'min_samples_split': 10,\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "# Time model parameters\n",
        "time_params = {\n",
        "    'n_estimators': 450,\n",
        "    'class_weight': 'balanced',\n",
        "    'max_depth': 12,\n",
        "    'max_features': 'sqrt',\n",
        "    'min_samples_leaf': 3,\n",
        "    'min_samples_split': 10,\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "print(\"Training distance model...\")\n",
        "distance_model = RandomForestClassifier(**distance_params)\n",
        "distance_model.fit(X_train_dist, y_train_dist)\n",
        "print(f\"✓ Distance model trained ({distance_params['n_estimators']} trees)\")\n",
        "\n",
        "print(\"\\nTraining time model...\")\n",
        "time_model = RandomForestClassifier(**time_params)\n",
        "time_model.fit(X_train_time, y_train_time)\n",
        "print(f\"✓ Time model trained ({time_params['n_estimators']} trees)\")"
      ],
      "metadata": {
        "id": "train_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluate Models"
      ],
      "metadata": {
        "id": "evaluate"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn,\n",
        "        'Sensitivity': tp / (tp + fn) * 100,\n",
        "        'Specificity': tn / (tn + fp) * 100,\n",
        "        'Precision': tp / (tp + fp) * 100,\n",
        "        'Accuracy': (tp + tn) / len(y_test) * 100,\n",
        "        'F1-Score': f1_score(y_test, y_pred) * 100,\n",
        "        'AUC': roc_auc_score(y_test, y_proba) * 100\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"{model_name} RESULTS\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"  TP: {tp:,}  FP: {fp:,}\")\n",
        "    print(f\"  FN: {fn:,}  TN: {tn:,}\")\n",
        "    print(f\"\\nMetrics:\")\n",
        "    print(f\"  AUC:         {metrics['AUC']:.1f}%\")\n",
        "    print(f\"  Accuracy:    {metrics['Accuracy']:.1f}%\")\n",
        "    print(f\"  Sensitivity: {metrics['Sensitivity']:.1f}%\")\n",
        "    print(f\"  Specificity: {metrics['Specificity']:.1f}%\")\n",
        "    print(f\"  Precision:   {metrics['Precision']:.1f}%\")\n",
        "    print(f\"  F1-Score:    {metrics['F1-Score']:.1f}%\")\n",
        "    \n",
        "    return metrics, y_proba\n",
        "\n",
        "# Evaluate both models\n",
        "dist_metrics, dist_proba = evaluate_model(distance_model, X_test_dist, y_test_dist, \"DISTANCE MODEL\")\n",
        "time_metrics, time_proba = evaluate_model(time_model, X_test_time, y_test_time, \"TIME MODEL\")"
      ],
      "metadata": {
        "id": "evaluate_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Visualize Results"
      ],
      "metadata": {
        "id": "visualize"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Distance ROC\n",
        "fpr_dist, tpr_dist, _ = roc_curve(y_test_dist, dist_proba)\n",
        "axes[0].plot(fpr_dist, tpr_dist, 'b-', linewidth=2, \n",
        "             label=f'Model (AUC = {dist_metrics[\"AUC\"]:.1f}%)')\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('Distance Model ROC Curve')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Time ROC\n",
        "fpr_time, tpr_time, _ = roc_curve(y_test_time, time_proba)\n",
        "axes[1].plot(fpr_time, tpr_time, 'orange', linewidth=2,\n",
        "             label=f'Model (AUC = {time_metrics[\"AUC\"]:.1f}%)')\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title('Time Model ROC Curve')\n",
        "axes[1].legend(loc='lower right')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{MODEL_OUTPUT_DIR}roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"✓ ROC curves saved\")"
      ],
      "metadata": {
        "id": "plot_roc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "feature_names = [\n",
        "    'Straight-line Distance',\n",
        "    'Road Length Density (Origin)',\n",
        "    'Intersection Density (Dest)',\n",
        "    'Slope (%)',\n",
        "    'Elevation Difference',\n",
        "    'Population'\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "x = np.arange(len(feature_names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, distance_model.feature_importances_, width,\n",
        "               label='Distance Model', color='steelblue', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, time_model.feature_importances_, width,\n",
        "               label='Time Model', color='orange', alpha=0.8)\n",
        "\n",
        "ax.set_ylabel('Feature Importance')\n",
        "ax.set_title('Feature Importance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{MODEL_OUTPUT_DIR}feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"✓ Feature importance plot saved\")"
      ],
      "metadata": {
        "id": "plot_importance"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Save Models"
      ],
      "metadata": {
        "id": "save"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained models\n",
        "distance_model_path = f'{MODEL_OUTPUT_DIR}distance_model.joblib'\n",
        "time_model_path = f'{MODEL_OUTPUT_DIR}time_model.joblib'\n",
        "\n",
        "joblib.dump(distance_model, distance_model_path)\n",
        "joblib.dump(time_model, time_model_path)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"MODELS SAVED\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nDistance model: {distance_model_path}\")\n",
        "print(f\"Time model: {time_model_path}\")\n",
        "print(f\"\\nModel Summary:\")\n",
        "print(f\"  Distance Model - AUC: {dist_metrics['AUC']:.1f}%, Accuracy: {dist_metrics['Accuracy']:.1f}%\")\n",
        "print(f\"  Time Model - AUC: {time_metrics['AUC']:.1f}%, Accuracy: {time_metrics['Accuracy']:.1f}%\")"
      ],
      "metadata": {
        "id": "save_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download models (Colab)\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading models...\")\n",
        "files.download(distance_model_path)\n",
        "files.download(time_model_path)\n",
        "print(\"✓ Models downloaded\")"
      ],
      "metadata": {
        "id": "download_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Table (for paper)"
      ],
      "metadata": {
        "id": "summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary table\n",
        "summary_data = {\n",
        "    'Metric': ['True Positives (TP)', 'True Negatives (TN)', 'False Positives (FP)',\n",
        "               'False Negatives (FN)', 'Sensitivity (%)', 'Specificity (%)',\n",
        "               'Precision (%)', 'Accuracy (%)', 'F1-Score (%)', 'AUC (%)'],\n",
        "    'Distance Model': [\n",
        "        dist_metrics['TP'], dist_metrics['TN'], dist_metrics['FP'], dist_metrics['FN'],\n",
        "        f\"{dist_metrics['Sensitivity']:.1f}\", f\"{dist_metrics['Specificity']:.1f}\",\n",
        "        f\"{dist_metrics['Precision']:.1f}\", f\"{dist_metrics['Accuracy']:.1f}\",\n",
        "        f\"{dist_metrics['F1-Score']:.1f}\", f\"{dist_metrics['AUC']:.1f}\"\n",
        "    ],\n",
        "    'Time Model': [\n",
        "        time_metrics['TP'], time_metrics['TN'], time_metrics['FP'], time_metrics['FN'],\n",
        "        f\"{time_metrics['Sensitivity']:.1f}\", f\"{time_metrics['Specificity']:.1f}\",\n",
        "        f\"{time_metrics['Precision']:.1f}\", f\"{time_metrics['Accuracy']:.1f}\",\n",
        "        f\"{time_metrics['F1-Score']:.1f}\", f\"{time_metrics['AUC']:.1f}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\nTable 2: Statistical Validation Indices\")\n",
        "print(\"=\"*60)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Save table\n",
        "summary_df.to_csv(f'{MODEL_OUTPUT_DIR}validation_metrics.csv', index=False)\n",
        "print(f\"\\n✓ Table saved to {MODEL_OUTPUT_DIR}validation_metrics.csv\")"
      ],
      "metadata": {
        "id": "summary_table"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
